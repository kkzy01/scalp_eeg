{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SwaV import SwaV\n",
    "from LSTMDownStream import SupervisedDownstream\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from lightly.loss import SwaVLoss\n",
    "from lightly.models.modules import SwaVProjectionHead, SwaVPrototypes\n",
    "from lightly.models.modules.memory_bank import MemoryBankModule\n",
    "from lightly.transforms.swav_transform import SwaVTransform\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-train SwaV with some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/k/kuangzy/.local/lib/python3.11/site-packages/lightly/models/modules/memory_bank.py:89: UserWarning: Memory bank size 'size=512' does not specify feature dimension. It is recommended to set the feature dimension with 'size=(n, dim)' when creating the memory bank. Distributed training might fail if the feature dimension is not set.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: datasets/pascal_voc/VOCtrainval_11-May-2012.tar\n",
      "Extracting datasets/pascal_voc/VOCtrainval_11-May-2012.tar to datasets/pascal_voc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home1/k/kuangzy/.local/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name            | Type               | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | backbone        | Sequential         | 23.5 M | train\n",
      "1 | projection_head | SwaVProjectionHead | 4.5 M  | train\n",
      "2 | prototypes      | SwaVPrototypes     | 264 K  | train\n",
      "3 | queues          | ModuleList         | 0      | train\n",
      "4 | criterion       | SwaVLoss           | 0      | train\n",
      "---------------------------------------------------------------\n",
      "28.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 M    Total params\n",
      "112.932   Total estimated model params size (MB)\n",
      "163       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home1/k/kuangzy/.local/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (44) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 44/44 [12:06<00:00,  0.06it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 44/44 [12:10<00:00,  0.06it/s, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model = SwaV()\n",
    "\n",
    "transform = SwaVTransform()\n",
    "# we ignore object detection annotations by setting target_transform to return 0\n",
    "dataset = datasets.VOCDetection(\n",
    "    \"datasets/pascal_voc\",\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    target_transform=lambda t: 0,\n",
    ")\n",
    "# or create a dataset from a folder containing images or videos:\n",
    "# dataset = LightlyDataset(\"path/to/folder\")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20, devices=1, accelerator=accelerator)\n",
    "trainer.fit(model=model, train_dataloaders=dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (900332655.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    $git push\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "$git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalpEEGDataset(Dataset):\n",
    "    def __init__(self, file_root, label_file, transform = None):\n",
    "        self.file_root = file_root\n",
    "        self.labels = pd.read_csv(file_root+label_file)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        eeg_id = os.path.join(self.file_root,)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(\"../EEGData/labels.csv\")\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ResNet trained with SSL to use with LSTM for final prediction in this way\n",
    "swav = SwaV.load_from_checkpoint(checkpoint_path='/home1/k/kuangzy/scalp-eeg-1/CNN-LSTM/lightning_logs/version_1/checkpoints/epoch=19-step=880.ckpt')\n",
    "model = SupervisedDownstream(swav.backbone)\n",
    "sd = SupervisedDownstream(model)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
